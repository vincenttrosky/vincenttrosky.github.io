<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>YOLO | Vincent Trosky</title>
    <link>http://localhost:1313/tags/yolo/</link>
      <atom:link href="http://localhost:1313/tags/yolo/index.xml" rel="self" type="application/rss+xml" />
    <description>YOLO</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Fri, 13 Sep 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu7729264130191091259.png</url>
      <title>YOLO</title>
      <link>http://localhost:1313/tags/yolo/</link>
    </image>
    
    <item>
      <title>Improving YOLO V2</title>
      <link>http://localhost:1313/project/yolo_v2v3/</link>
      <pubDate>Fri, 13 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/yolo_v2v3/</guid>
      <description>&lt;!-- This work is driven by the results in my [previous paper](/publication/conference-paper/) on LLMs.






  
    
  

&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.&lt;/span&gt;
&lt;/div&gt;

Add the publication&#39;s **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). --&gt;
&lt;figure style=&#34;width: 100%; margin: 0;&#34;&gt;
    &lt;img src=&#34;featured.png&#34; style=&#34;width: 100%; display: block;&#34;&gt;
    &lt;figcaption style=&#34;text-align: center;&#34;&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;See the &lt;a href=&#34;Final Project_ Improving YOLOv2.pdf&#34;&gt;PDF above&lt;/a&gt; for the full report!&lt;/p&gt;
&lt;p&gt;“You Only Look Once version 2” (YOLOv2) is an object detection algorithm capable of
completing real-time object detection tasks. Developed by Joseph Redmon and Ali Farhadi, YOLOv2 is a deep learning-based algorithm that approaches object
detection as a single regression problem. After dividing an input image into a grid, the algorithm
uses anchor bounding boxes around objects and produces class probabilities for each grid cell.
The algorithm then uses this data and performs feature extraction based on prior training over a
set of image classes using a deep convolutional neural network (CNN).&lt;/p&gt;
&lt;p&gt;In this project, I attempted to modify the the Darknet-19 backbone used by YOLOv2. All Max Pooling layers in the backbone were replaced by convolutional layers in an attempt to increase the amount of relevant information being transmitted between layer input and output. My attempt did not outperform the baseline model at the 50 epoch checkpoint, as the mean average precision (mAP) decreased from 70% to 28% and the frames per second (FPS) rate decreased from 71.88 to 62.63. Eventually, I would like to go back and attempt to replace the Darknet-19 backbone with a residual backbone like ResNet or modify the loss function to improve performance.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
